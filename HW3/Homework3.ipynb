{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    def __init__(self, n_epochs=5, train_batch_size=64, test_batch_size=1000, learning_rate=0.01, momentum=0.8):\n",
    "        torch.manual_seed(9)\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        self.n_epochs = n_epochs\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.log_interval = 10\n",
    "\n",
    "        self.train_configs = {'batch_size': self.train_batch_size}\n",
    "        self.test_configs = {'batch_size': self.test_batch_size}\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "            cuda_configs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
    "            self.train_configs.update(cuda_configs)\n",
    "            self.test_configs.update(cuda_configs)\n",
    "\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "    \n",
    "    def get_train_kwargs(self):\n",
    "        return self.train_configs\n",
    "    \n",
    "    def get_test_kwargs(self):\n",
    "        return self.test_configs\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        # output = F.softmax(x, dim=1)\n",
    "        output = x\n",
    "        return output\n",
    "\n",
    "def train(args, model, train_loader, optimizer, epoch, criterion):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(args.device), target.to(args.device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "def validate(model, configs, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(configs.device), target.to(configs.device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f'\\nValidation Average Loss: {val_loss:.4f}; Validation Average Accuracy: {correct}/{len(val_loader.dataset)} ({100. * correct / len(val_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "def inference(model, configs, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(configs.device), target.to(configs.device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest Average Loss: {test_loss:.4f};Test Average Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.339320\n",
      "Train Epoch: 0 [640/60000 (1%)]\tLoss: 1.826767\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 1.577013\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 1.287614\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 1.060851\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 1.025056\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.840179\n",
      "Train Epoch: 0 [4480/60000 (7%)]\tLoss: 0.786345\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.908402\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.757845\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.656764\n",
      "Train Epoch: 0 [7040/60000 (12%)]\tLoss: 0.687619\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.690501\n",
      "Train Epoch: 0 [8320/60000 (14%)]\tLoss: 0.631172\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.517873\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.555379\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.671723\n",
      "Train Epoch: 0 [10880/60000 (18%)]\tLoss: 0.477449\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.677540\n",
      "Train Epoch: 0 [12160/60000 (20%)]\tLoss: 0.610699\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.510884\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.383350\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.619306\n",
      "Train Epoch: 0 [14720/60000 (25%)]\tLoss: 0.754166\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.473628\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.686291\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.560986\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.343095\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.391676\n",
      "Train Epoch: 0 [18560/60000 (31%)]\tLoss: 0.478318\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.482610\n",
      "Train Epoch: 0 [19840/60000 (33%)]\tLoss: 0.407133\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.285382\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.385049\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.173100\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.377365\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.506892\n",
      "Train Epoch: 0 [23680/60000 (39%)]\tLoss: 0.641888\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.384843\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.448765\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.351286\n",
      "Train Epoch: 0 [26240/60000 (44%)]\tLoss: 0.428825\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.553461\n",
      "Train Epoch: 0 [27520/60000 (46%)]\tLoss: 0.257572\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.444035\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.283947\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.309546\n",
      "Train Epoch: 0 [30080/60000 (50%)]\tLoss: 0.588735\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.481294\n",
      "Train Epoch: 0 [31360/60000 (52%)]\tLoss: 0.568777\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.409951\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.466688\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.382128\n",
      "Train Epoch: 0 [33920/60000 (57%)]\tLoss: 0.202213\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.377550\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.430646\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.361346\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.374764\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.411619\n",
      "Train Epoch: 0 [37760/60000 (63%)]\tLoss: 0.382621\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.283885\n",
      "Train Epoch: 0 [39040/60000 (65%)]\tLoss: 0.208889\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.396224\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.295012\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.497489\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.321967\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.328365\n",
      "Train Epoch: 0 [42880/60000 (71%)]\tLoss: 0.501128\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.358546\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.299005\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.446529\n",
      "Train Epoch: 0 [45440/60000 (76%)]\tLoss: 0.679211\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.488080\n",
      "Train Epoch: 0 [46720/60000 (78%)]\tLoss: 0.401704\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.344511\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.220147\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.319107\n",
      "Train Epoch: 0 [49280/60000 (82%)]\tLoss: 0.222787\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.341296\n",
      "Train Epoch: 0 [50560/60000 (84%)]\tLoss: 0.501274\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.426060\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.276014\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.143380\n",
      "Train Epoch: 0 [53120/60000 (88%)]\tLoss: 0.405125\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.162320\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.318875\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.302590\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.411878\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.279069\n",
      "Train Epoch: 0 [56960/60000 (95%)]\tLoss: 0.347463\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.451524\n",
      "Train Epoch: 0 [58240/60000 (97%)]\tLoss: 0.155221\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.062679\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.083001\n",
      "\n",
      "Validation Average Loss: 0.0003; Validation Average Accuracy: 9032/10000 (90%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.285679\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.390158\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.383693\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.233491\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.231973\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.280646\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.177287\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.252468\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.604477\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.246586\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.294803\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.232427\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.300188\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.222898\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.270343\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.335189\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.503984\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.200215\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.629317\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.494490\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.258155\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.221795\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.508753\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.615762\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.234664\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.486820\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.456232\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.182809\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.292995\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.383804\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.367183\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.232139\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.184013\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.313840\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.098214\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.257412\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.413302\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.570192\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.251858\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.326842\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.253001\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.350993\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.474163\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.226658\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.325113\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.173233\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.224649\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.425899\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.384652\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.482067\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.353425\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.427209\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.339352\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.151586\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.325572\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.358492\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.283313\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.287370\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.398721\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.310577\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.224166\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.169708\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.328360\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.281888\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.460852\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.246178\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.255761\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.421501\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.330649\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.219565\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.408954\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.622982\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.466527\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.375517\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.281130\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.179205\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.283422\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.205165\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.289595\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.438919\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.379987\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.218804\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.116256\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.365952\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.130991\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.285906\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.267752\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.398289\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.225440\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.300975\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.463260\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.133403\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.054791\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.064671\n",
      "\n",
      "Validation Average Loss: 0.0003; Validation Average Accuracy: 9109/10000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.227326\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.349052\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.360053\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.201728\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.196661\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.271622\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.135960\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.228479\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.567836\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.218710\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.277786\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.201958\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.267935\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.186827\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.236981\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.300075\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.453063\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.177832\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.597822\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.479130\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.219222\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.202395\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.469817\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.616531\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.197458\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.463869\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.432713\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.155795\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.270185\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.359744\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.334158\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.195333\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.167537\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.304618\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.087189\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.235983\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.403670\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.553714\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.219011\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.297506\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.236008\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.332531\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.465833\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.230878\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.288091\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.149699\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.198933\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.392001\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.355282\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.453421\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.338045\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.423889\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.346251\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.139582\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.310815\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.335247\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.260513\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.258387\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.407160\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.289571\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.205662\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.158473\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.312163\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.282605\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.448398\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.215798\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.236825\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.378296\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.330818\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.196305\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.396832\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.600250\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.455973\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.375964\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.259616\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.166524\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.274689\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.203339\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.268761\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.408834\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.358217\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.197705\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.109755\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.356269\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.121248\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.270964\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.247077\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.390603\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.206245\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.279452\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.458645\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.126052\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.052478\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.058843\n",
      "\n",
      "Validation Average Loss: 0.0003; Validation Average Accuracy: 9149/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = Configs(n_epochs=3, train_batch_size=64, test_batch_size=1000, learning_rate=0.01, momentum=0.5)\n",
    "mnist_train = datasets.MNIST(root='./datasets', train=True, download=True, transform=configs.transformer)\n",
    "mnist_test = datasets.MNIST(root='./datasets', train=False, download=True, transform=configs.transformer)\n",
    "train_loader = DataLoader(mnist_train, **configs.get_train_kwargs())\n",
    "test_loader = DataLoader(mnist_test, **configs.get_test_kwargs())\n",
    "model = Net().to(configs.device)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=configs.learning_rate)\n",
    "for epoch in range(configs.n_epochs):\n",
    "    train(configs, model, train_loader, optimizer, epoch, criterion)\n",
    "    validate(model, configs, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb8a66da18cb9a08ef1faf318ea6b3f88bd6d51d30c0e91ea3252e02ca9dbf8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
